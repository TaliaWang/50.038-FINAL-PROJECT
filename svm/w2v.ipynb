{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1tWLmeKQ1bg84OvraKktgxdPHZinAHO3_","authorship_tag":"ABX9TyNbhbLDAstswlXKibA7UjlE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","!pip install gensim==3.8.3\n","import pickle\n","import gensim.downloader\n","from gensim.models import Word2Vec\n","import nltk.data\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import logging\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","from sklearn import decomposition\n","print(gensim.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GviBpvXP51pA","executionInfo":{"status":"ok","timestamp":1680241083828,"user_tz":-480,"elapsed":15381,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"dad41c5e-b35d-4986-f54b-69b2b78f262f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.9/dist-packages (3.8.3)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.10.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.16.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (6.3.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.22.4)\n","3.8.3\n"]}]},{"cell_type":"code","source":["url = \"https://raw.githubusercontent.com/soujanyaporia/MUStARD/master/data/sarcasm_data.json\"\n","df = pd.read_json(url,orient='index')\n","df.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"0TCHnA4NdOD8","executionInfo":{"status":"ok","timestamp":1680241805051,"user_tz":-480,"elapsed":857,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"e1e0ec2f-be61-4da2-9034-62562b311eef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              utterance  speaker  \\\n","160   It's just a privilege to watch your mind at work.  SHELDON   \n","170   I don't think I'll be able to stop thinking ab...    PENNY   \n","180   Since it's not bee season, you can have my epi...  SHELDON   \n","190   Lois Lane is falling, accelerating at an initi...  SHELDON   \n","1105  I'm just inferring this is a couch because the...  SHELDON   \n","\n","                                                context  \\\n","160   [I never would have identified the fingerprint...   \n","170   [This is one of my favorite places to kick bac...   \n","180   [Here we go. Pad thai, no peanuts., But does i...   \n","190   [A marathon? How many Superman movies are ther...   \n","1105  [Great Caesar's ghost, look at this place., So...   \n","\n","                                       context_speakers show  sarcasm  \n","160                                  [LEONARD, SHELDON]  BBT     True  \n","170   [HOWARD, PENNY, HOWARD, HOWARD, HOWARD, PENNY,...  BBT     True  \n","180                          [LEONARD, HOWARD, LEONARD]  BBT    False  \n","190   [PENNY, SHELDON, PENNY, SHELDON, SHELDON, PENN...  BBT    False  \n","1105  [SHELDON, LEONARD, SHELDON, SHELDON, SHELDON, ...  BBT     True  "],"text/html":["\n","  <div id=\"df-e317bff2-699a-4ade-afe9-69696acb3516\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>utterance</th>\n","      <th>speaker</th>\n","      <th>context</th>\n","      <th>context_speakers</th>\n","      <th>show</th>\n","      <th>sarcasm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>160</th>\n","      <td>It's just a privilege to watch your mind at work.</td>\n","      <td>SHELDON</td>\n","      <td>[I never would have identified the fingerprint...</td>\n","      <td>[LEONARD, SHELDON]</td>\n","      <td>BBT</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>I don't think I'll be able to stop thinking ab...</td>\n","      <td>PENNY</td>\n","      <td>[This is one of my favorite places to kick bac...</td>\n","      <td>[HOWARD, PENNY, HOWARD, HOWARD, HOWARD, PENNY,...</td>\n","      <td>BBT</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>180</th>\n","      <td>Since it's not bee season, you can have my epi...</td>\n","      <td>SHELDON</td>\n","      <td>[Here we go. Pad thai, no peanuts., But does i...</td>\n","      <td>[LEONARD, HOWARD, LEONARD]</td>\n","      <td>BBT</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>Lois Lane is falling, accelerating at an initi...</td>\n","      <td>SHELDON</td>\n","      <td>[A marathon? How many Superman movies are ther...</td>\n","      <td>[PENNY, SHELDON, PENNY, SHELDON, SHELDON, PENN...</td>\n","      <td>BBT</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1105</th>\n","      <td>I'm just inferring this is a couch because the...</td>\n","      <td>SHELDON</td>\n","      <td>[Great Caesar's ghost, look at this place., So...</td>\n","      <td>[SHELDON, LEONARD, SHELDON, SHELDON, SHELDON, ...</td>\n","      <td>BBT</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e317bff2-699a-4ade-afe9-69696acb3516')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e317bff2-699a-4ade-afe9-69696acb3516 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e317bff2-699a-4ade-afe9-69696acb3516');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# plt.figure(figsize=(10,4))\n","# df[\"sarcasm\"].value_counts().plot(kind='bar');"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"Ouqp1Ta6dZ04","executionInfo":{"status":"ok","timestamp":1680239917604,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"0b4c11b1-a62d-4009-bf70-55a6fbac27bc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# w10 lab\n","%%time\n","\n","wv1 = gensim.downloader.load('word2vec-google-news-300')\n","wv1.init_sims(replace=True)\n","print('Model loaded')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5OTG8oB3fnUV","executionInfo":{"status":"ok","timestamp":1680241167065,"user_tz":-480,"elapsed":83241,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"4be8830d-7242-4d6e-a974-117730ff6a49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded\n","CPU times: user 1min 2s, sys: 8.98 s, total: 1min 11s\n","Wall time: 1min 23s\n"]}]},{"cell_type":"code","source":["file = open('drive/MyDrive/wv_gnews300_383', 'wb')\n","\n","# dump information to that file\n","pickle.dump(wv1, file)\n","\n","# close the file\n","file.close()"],"metadata":{"id":"WGcWAP6pixTT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# open a file, where you stored the pickled data\n","file = open('drive/MyDrive/wv_gnews300_383', 'rb')\n","\n","# dump information to that file\n","wv = pickle.load(file)\n","\n","# close the file\n","file.close()"],"metadata":{"id":"71aD5NLzjQTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# w10 lab\n","nltk.download('punkt')\n","\n","def w2v_tokenize_text(text):\n","    # create tokens, a list of words, for each post. This function will do some cleaning based on English language\n","    tokens = []\n","    for sent in nltk.sent_tokenize(text, language='english'):\n","        for word in nltk.word_tokenize(sent, language='english'):\n","            if len(word) < 2:\n","                continue\n","            tokens.append(word)\n","    return tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxHJpF0af8V4","executionInfo":{"status":"ok","timestamp":1680241793754,"user_tz":-480,"elapsed":322,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"242314c3-038c-4f84-a395-2af00d250bbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["# w10 lab\n","train, test = train_test_split(df, test_size=0.3, random_state = 42)\n","\n","test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['utterance']), axis=1).values\n","train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['utterance']), axis=1).values"],"metadata":{"id":"PzqjkNWxgBYs","executionInfo":{"status":"error","timestamp":1680244296249,"user_tz":-480,"elapsed":344,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"colab":{"base_uri":"https://localhost:8080/","height":364},"outputId":"add0ef11-bb4e-4dfb-9859-31662d6478d0"},"execution_count":20,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-efdc9aecabf8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw2v_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw2v_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8846\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8847\u001b[0m         )\n\u001b[0;32m-> 8848\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8850\u001b[0m     def applymap(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-efdc9aecabf8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw2v_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw2v_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-07ed0303ab75>\u001b[0m in \u001b[0;36mw2v_tokenize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# create tokens, a list of words, for each post. This function will do some cleaning based on English language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \"\"\"\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_last_whitespace_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_last_whitespace_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \"\"\"\n\u001b[1;32m   1458\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_match_potential_end_contexts\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mprevious_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mprevious_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0;31m# Get the slice of the previous word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"]}]},{"cell_type":"code","source":["test_tokenized_context = test.apply(lambda r: w2v_tokenize_text(\" \".join(r['context'])), axis=1).values\n","train_tokenized_context = train.apply(lambda r: w2v_tokenize_text(\" \".join(r['context'])), axis=1).values"],"metadata":{"id":"dijYyzkeXsif","executionInfo":{"status":"ok","timestamp":1680244439831,"user_tz":-480,"elapsed":737,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#w10 lab\n","def word_averaging(wv, words):\n","    # averages a set of words 'words' given their wordvectors 'wv'\n","    \n","    all_words, mean = set(), []\n","    \n","    # for each word in the list of words\n","    for word in words:\n","        # if the words are alread vectors, then just append them\n","        if isinstance(word, np.ndarray):\n","            mean.append(word)\n","        # if not: first get the vector embedding for the words\n","        elif word in wv.vocab:\n","            mean.append(wv.syn0norm[wv.vocab[word].index])\n","            all_words.add(wv.vocab[word].index)\n","\n","    \n","    if not mean:\n","        # error handling in case mean cannot be calculated\n","        logging.warning(\"cannot compute similarity with no input %s\", words)\n","        return np.zeros(wv.vector_size,)\n","\n","    # use gensim's method to calculate the mean of all the words appended to mean list\n","    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n","    return mean\n","\n","def  word_averaging_list(wv, text_list):\n","    return np.vstack([word_averaging(wv, post) for post in text_list ])"],"metadata":{"id":"5j8DVzSifyYT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# w10 lab\n","X_train_word_average = word_averaging_list(wv,train_tokenized)\n","X_test_word_average = word_averaging_list(wv,test_tokenized)\n","\n","X_train_word_average_context = word_averaging_list(wv,train_tokenized_context)\n","X_test_word_average_context = word_averaging_list(wv,test_tokenized_context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JiR9a8-Mui82","executionInfo":{"status":"ok","timestamp":1680244511553,"user_tz":-480,"elapsed":1355,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"fd912b34-7366-47bc-f7b0-b346162b9ac2"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c644c9e63e6f>:14: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n","  mean.append(wv.syn0norm[wv.vocab[word].index])\n","WARNING:root:cannot compute similarity with no input ['Uh-huh']\n","WARNING:root:cannot compute similarity with no input ['Uh-huh']\n","WARNING:root:cannot compute similarity with no input ['Pheebs']\n"]}]},{"cell_type":"code","source":["file = open('drive/MyDrive/wv_Xtrain', 'wb')\n","\n","# dump information to that file\n","pickle.dump(X_train_word_average, file)\n","\n","# close the file\n","file.close()\n","\n","file = open('drive/MyDrive/wv_Xtext', 'wb')\n","\n","# dump information to that file\n","pickle.dump(X_test_word_average, file)\n","\n","# close the file\n","file.close()"],"metadata":{"id":"4_HVYwYBN4El"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file = open('drive/MyDrive/wv_Xtrain_context', 'wb')\n","\n","# dump information to that file\n","pickle.dump(X_train_word_average_context, file)\n","\n","# close the file\n","file.close()\n","\n","file = open('drive/MyDrive/wv_Xtext_context', 'wb')\n","\n","# dump information to that file\n","pickle.dump(X_test_word_average_context, file)\n","\n","# close the file\n","file.close()"],"metadata":{"id":"EC-I5UGBYBe7","executionInfo":{"status":"ok","timestamp":1680244492799,"user_tz":-480,"elapsed":2,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["pca = decomposition.PCA(n_components=1)\n","pca.fit(X_train_word_average)\n","utterance_train = pca.transform(X_train_word_average)\n","\n","pca = decomposition.PCA(n_components=1)\n","pca.fit(X_test_word_average)\n","utterance_test = pca.transform(X_test_word_average)"],"metadata":{"id":"YG72L8YdO5OD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = np.concatenate([X_train_word_average, X_train_word_average_context], axis=1)\n","X_test = np.concatenate([X_test_word_average, X_test_word_average_context], axis=1)"],"metadata":{"id":"YgdpOKrgYLyh","executionInfo":{"status":"ok","timestamp":1680244657146,"user_tz":-480,"elapsed":412,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["clf = SVC()\n","svm = clf.fit(X_train, train['sarcasm'])\n","y_pred = svm.predict(X_test)\n","\n","print(classification_report(test['sarcasm'], y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yArMCKDVgZYr","executionInfo":{"status":"ok","timestamp":1680244680376,"user_tz":-480,"elapsed":728,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"cae73c00-b371-4d7a-8e65-d87801b8ff33"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       False       0.57      0.70      0.63        94\n","        True       0.70      0.57      0.62       113\n","\n","    accuracy                           0.63       207\n","   macro avg       0.63      0.63      0.63       207\n","weighted avg       0.64      0.63      0.63       207\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8mxfs7-3cbZc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7SSQb-i0cbne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2nsydiQhcbvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers \n","\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import pickle\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report"],"metadata":{"id":"eJkaF6krgbyk","executionInfo":{"status":"ok","timestamp":1680245402438,"user_tz":-480,"elapsed":16509,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2c2b7b8-226a-416d-cecd-8de6c4c29190"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)"],"metadata":{"id":"b_SFg026gk75","executionInfo":{"status":"ok","timestamp":1680247676517,"user_tz":-480,"elapsed":7804,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a55db33-89a7-41f5-f9e6-327f5ce1f9f4"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["url = \"https://raw.githubusercontent.com/soujanyaporia/MUStARD/master/data/sarcasm_data.json\"\n","df = pd.read_json(url,orient='index')\n","df_train, df_test = train_test_split(df, test_size=0.3, random_state = 42)"],"metadata":{"id":"UfzKqkfNaWMy","executionInfo":{"status":"ok","timestamp":1680247679052,"user_tz":-480,"elapsed":560,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# https://towardsdatascience.com/feature-extraction-with-bert-for-text-classification-533dde44dc2f\n","tokenized_train = tokenizer(df_train[\"utterance\"].values.tolist(), padding = True, truncation = True, return_tensors=\"pt\")\n","tokenized_val = tokenizer(df_test[\"utterance\"].values.tolist() , padding = True, truncation = True,  return_tensors=\"pt\")\n","\n","print(tokenized_train.keys())\n","\n","#move on device (GPU)\n","tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n","tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}\n","\n","with torch.no_grad():\n","  hidden_train = model(**tokenized_train) #dim : [batch_size(nr_sentences), tokens, emb_dim]\n","  hidden_val = model(**tokenized_val)\n","\n","#get only the [CLS] hidden states\n","cls_train = hidden_train.last_hidden_state[:,0,:]\n","cls_val = hidden_val.last_hidden_state[:,0,:]\n","\n","file = open('drive/MyDrive/bert_train', 'wb')\n","\n","# dump information to that file\n","pickle.dump(cls_train, file)\n","\n","# close the file\n","file.close()\n","\n","file = open('drive/MyDrive/bert_test', 'wb')\n","\n","# dump information to that file\n","pickle.dump(cls_val, file)\n","\n","# close the file\n","file.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"zDvxIxCpeP-J","executionInfo":{"status":"error","timestamp":1680247691288,"user_tz":-480,"elapsed":9316,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"f5e33e96-9d25-4adc-c59c-63f7f3f2b7a2"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['input_ids', 'attention_mask'])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-46-bb73fcf8769c>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n","<ipython-input-46-bb73fcf8769c>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-bb73fcf8769c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mhidden_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokenized_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#dim : [batch_size(nr_sentences), tokens, emb_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mhidden_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokenized_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    584\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         sa_output = self.attention(\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, q_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, q_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["df_train[\"context\"] = df_train.apply(lambda r:\" \".join(r['context']), axis=1)\n","df_test[\"context\"] = df_test.apply(lambda r:\" \".join(r['context']), axis=1)"],"metadata":{"id":"mM023p6Te3Tw","executionInfo":{"status":"ok","timestamp":1680246426939,"user_tz":-480,"elapsed":1024,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["df_train[\"utterance\"] "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"592vpR5ifXZi","executionInfo":{"status":"ok","timestamp":1680246441995,"user_tz":-480,"elapsed":380,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"e435c087-856e-4798-9cce-98579d235c95"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17442     The original title was \"A Rederivation of Maxw...\n","111723    Not much, but he seemed to be in a pretty good...\n","2447      It was an accident. Not like I was across the ...\n","258                                                    Why?\n","2191                                  So, you're just Bing?\n","                                ...                        \n","13064     When I have enough to destroy all the human to...\n","14603     Is it possible that she was going for your che...\n","111901    Yeah, good for you, Leonard. That's a lovely l...\n","2611                                      Just tell me how.\n","14477     I just want to ask you a few questions about H...\n","Name: utterance, Length: 483, dtype: object"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# https://towardsdatascience.com/feature-extraction-with-bert-for-text-classification-533dde44dc2f\n","tokenized_train = tokenizer(df_train[\"context\"].values.tolist(), padding = True, truncation = True, return_tensors=\"pt\")\n","tokenized_val = tokenizer(df_test[\"context\"].values.tolist() , padding = True, truncation = True,  return_tensors=\"pt\")\n","\n","print(tokenized_train.keys())\n","\n","#move on device (GPU)\n","tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n","tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}\n","\n","with torch.no_grad():\n","  hidden_train = model(**tokenized_train) #dim : [batch_size(nr_sentences), tokens, emb_dim]\n","  hidden_val = model(**tokenized_val)\n","\n","#get only the [CLS] hidden states\n","cls_train = hidden_train.last_hidden_state[:,0,:]\n","cls_val = hidden_val.last_hidden_state[:,0,:]\n","\n","file = open('drive/MyDrive/bert_train_context', 'wb')\n","\n","# dump information to that file\n","pickle.dump(cls_train, file)\n","\n","# close the file\n","file.close()\n","\n","file = open('drive/MyDrive/bert_test_context', 'wb')\n","\n","# dump information to that file\n","pickle.dump(cls_val, file)\n","\n","# close the file\n","file.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXinijF6bKPN","executionInfo":{"status":"ok","timestamp":1680246705912,"user_tz":-480,"elapsed":251633,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"c43d2ed7-37da-4a48-9497-0627006db136"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['input_ids', 'attention_mask'])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-31-97115821c4d7>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n","<ipython-input-31-97115821c4d7>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}\n"]}]},{"cell_type":"code","source":["file = open('drive/MyDrive/bert_train', 'rb')\n","emb_train_utterance = pickle.load(file)\n","file.close()\n","\n","file = open('drive/MyDrive/bert_test', 'rb')\n","emb_test_utterance = pickle.load(file)\n","file.close()\n","\n","file = open('drive/MyDrive/bert_train_context', 'rb')\n","emb_train_context = pickle.load(file)\n","file.close()\n","\n","file = open('drive/MyDrive/bert_test_context', 'rb')\n","emb_test_context = pickle.load(file)\n","file.close()"],"metadata":{"id":"bNRbkZYPecFa","executionInfo":{"status":"ok","timestamp":1680246837404,"user_tz":-480,"elapsed":2324,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","X_train = np.concatenate([emb_train_utterance, emb_train_context], axis=1)\n","X_test = np.concatenate([emb_test_utterance, emb_test_context], axis=1)"],"metadata":{"id":"fXi8s5O6f47i","executionInfo":{"status":"ok","timestamp":1680246837405,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4MObU5ldhCM8","executionInfo":{"status":"ok","timestamp":1680247289813,"user_tz":-480,"elapsed":6,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"e414c420-61cb-4b05-a498-dd95c6f2f1dd"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.00314103e-01,  1.01008061e-02, -1.30202025e-01, ...,\n","         1.43253128e-04,  4.89130944e-01,  4.48318779e-01],\n","       [-3.41278911e-02, -9.46181491e-02,  3.03367153e-03, ...,\n","         1.40088364e-01,  4.81019288e-01,  3.05446684e-01],\n","       [ 2.65692896e-03, -3.10546570e-02, -1.05267465e-01, ...,\n","        -1.79545224e-01,  5.47968149e-01,  1.98676154e-01],\n","       ...,\n","       [-3.00203301e-02,  5.64074032e-02, -2.91891173e-02, ...,\n","        -1.01415351e-01,  3.46784502e-01,  3.42982709e-01],\n","       [ 5.35154864e-02, -1.81717187e-01,  2.04388928e-02, ...,\n","         8.48387275e-03,  5.08921802e-01,  3.48097384e-01],\n","       [ 1.43476855e-02, -2.30267569e-02, -2.18402043e-01, ...,\n","         8.22134688e-02,  6.07035160e-01,  3.30790967e-01]], dtype=float32)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","clf = SVC()\n","svm = clf.fit(X_train, df_train['sarcasm'])\n","y_pred = svm.predict(X_test)\n","\n","print(classification_report(df_test['sarcasm'], y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMF4TNt3dSEW","executionInfo":{"status":"ok","timestamp":1680246888363,"user_tz":-480,"elapsed":825,"user":{"displayName":"Ally Z","userId":"13265978477856964852"}},"outputId":"bee75cea-6a9c-44c7-fa85-77c22fc0161e"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       False       0.57      0.70      0.63        94\n","        True       0.69      0.56      0.62       113\n","\n","    accuracy                           0.62       207\n","   macro avg       0.63      0.63      0.62       207\n","weighted avg       0.64      0.62      0.62       207\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fhZRABYId2lS"},"execution_count":null,"outputs":[]}]}